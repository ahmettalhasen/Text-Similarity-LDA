{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "projectCleaning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmettalhasen/Text-Similarity-LDA/blob/master/projectCleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcvQXnsGpVAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import time\n",
        "\n",
        "import gensim\n",
        "from gensim.models import LdaModel\n",
        "from gensim import models, corpora, similarities\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk import FreqDist\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from scipy.stats import entropy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set_style(\"darkgrid\")\n",
        "\n",
        "!pip install pyspellchecker # For correcting the spell mistakes\n",
        "from spellchecker import SpellChecker\n",
        "\n",
        "!pip install langdetect\n",
        "from langdetect import detect \n",
        "from langdetect.lang_detect_exception import LangDetectException"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cm-WTedsiHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Importing the dataset\n",
        "df = pd.read_csv('gdrive/My Drive/summer2019/support_forum_questions.csv',sep=\"|\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62QdUZorui66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dropping unnecessary columns ad removing entries with na\n",
        "df.dropna(axis = 0, inplace = True)\n",
        "df.isnull().sum()\n",
        "df = df.sample(frac=1.0)\n",
        "df = df.reset_index(drop=True)\n",
        "df = df.drop('login', axis=1)\n",
        "df = df.drop('added', axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXaINw450vYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Clearing Html function\n",
        "def clearhtml(raw_html):\n",
        "    \"\"\"\n",
        "    Function that cleans html code\n",
        "    \"\"\"\n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleantext = re.sub(cleanr, ' ', raw_html)\n",
        "    cleantext = re.sub('\\n', ' ', cleantext)\n",
        "    cleantext = re.sub('\\r', ' ', cleantext)\n",
        "    cleantext = re.sub('&nbsp', ' ', cleantext)\n",
        "    return cleantext\n",
        "\n",
        "def initial_clean(text):\n",
        "    \"\"\"\n",
        "    Function that cleans emails, websites and any symbols/punctuations\n",
        "    \"\"\"\n",
        "    text = re.sub(\"((\\S+)?(http(s)?)(\\S+))|((\\S+)?(www)(\\S+))|((\\S+)?(\\@)(\\S+)?)|((\\S+)?(.com)(\\S+)?)\", \" \", text)\n",
        "    text = text.lower() \n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\"jotform\", \" form \", text)\n",
        "    text = re.sub(\"[^a-zA-Z ]\", \" \", text)  \n",
        "    return text\n",
        "\n",
        "def first_preprocess(text):\n",
        "    \"\"\"\n",
        "    Function that applies clearhtml and initial_clean\n",
        "    \"\"\"\n",
        "    return initial_clean(clearhtml(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyFPS5R8KwPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Preprocess I\n",
        "t1 = time.time()\n",
        "df['question'] = df['question'].apply(first_preprocess)\n",
        "df['details'] = df['details'].apply(first_preprocess)\n",
        "df['quest'] = df['question'] + ' ' + df['details']\n",
        "#Deleting the questions less than 30 character size --> They are all test entries or spams\n",
        "df = df[df.quest.str.len() > 30 ]\n",
        "t2 = time.time()\n",
        "print(\"Time to clean Html\", len(df), \"articles:\", (t2-t1)/60, \"min\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV6fA3dnMhz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Filtering the non-english questions out\n",
        "\n",
        "def filter_language(text):\n",
        "    \"\"\"\n",
        "    Function that applies all three functions abov\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return detect(text)\n",
        "    except LangDetectException:\n",
        "        pass\n",
        "      \n",
        "#Preprocess II     \n",
        "t3 = time.time()     \n",
        "df = df[df.quest.apply(filter_language) == 'en']\n",
        "t4 = time.time()\n",
        "print(\"Time to filtering non-english questions took \", (t4-t3)/60, \"min\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNHCFPY_MfiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def tokenizer(text):\n",
        "    \"\"\"\n",
        "    Function that tokenizes words\n",
        "    \"\"\"\n",
        "    text = nltk.word_tokenize(text)\n",
        "    return text  \n",
        "  \n",
        "stop_words = stopwords.words('english')\n",
        "def remove_stop_words_and_junk(text):\n",
        "    \"\"\"\n",
        "    Function that removes all stopwords and undesired ones from text\n",
        "    \"\"\"\n",
        "    #Deleting undesired words\n",
        "    undesiredWords = ['would', 'hi', 'hello', 'thank', 'ive', 'havent', 'hasnt', \n",
        "                  'hadnt', 'arent', 'isnt', 'wouldnt', 'dont', 'werent', \n",
        "                  'couldnt', 'wont', 'cant', 'didnt', \"doesnt\", 'without',\n",
        "                  'please','thanks', 'could']\n",
        "    undesiredWords = set(undesiredWords)\n",
        "    \n",
        "    return [word for word in text if word not in stop_words and word not in undesiredWords]\n",
        "\n",
        "def second_preprocess(text):\n",
        "    \"\"\"\n",
        "    Function that tokenizes and removes stop words and junk some words\n",
        "    \"\"\"\n",
        "    return remove_stop_words_and_junk(tokenizer(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OdJp2nOLjcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Preprocess III \n",
        "t5 = time.time()\n",
        "df['tokenized'] = df['quest'].apply(second_preprocess)\n",
        "t6 = time.time()\n",
        "print(\"Time to tokenize and perfom the removals for\", len(df), \"questions took \", (t6-t5)/60, \"min\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQMEj4GbGyDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = [word for row in list(df.tokenized) for word in row]\n",
        "freqDist = FreqDist(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNHZYgaOG7zz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Spell Checker is not used since this operation is too expensive\n",
        "#Also this method corrupts some valuable words such as 'css'\n",
        "spell = SpellChecker() \n",
        "def spelling_mistake_corrector(word):\n",
        "    \"\"\"\n",
        "    Function that corrects the spelling mistake.\n",
        "    Corrects if the number of occurences of the correct form is greater than\n",
        "    the number of occurences of the original form in order to prevent miscorrection\n",
        "    of some words.\n",
        "    \"\"\"\n",
        "    checkedWord = spell.correction(word)\n",
        "    if freqDist[checkedWord] >= freqDist[word]:\n",
        "        word = checkedWord\n",
        "    return word\n",
        "  \n",
        "def correctorForAll(text):\n",
        "    \"\"\"\n",
        "    Function that applies spelling_mistake_corrector to all words\n",
        "    \"\"\"\n",
        "    text = [spelling_mistake_corrector(word) for word in text]\n",
        "    return text\n",
        "\n",
        "#Option 1\n",
        "#Since our purpose is to get a good topic distribution. Any of a word yields \n",
        "#to the same topic. Thus this gives better results\n",
        "stemmer = PorterStemmer()\n",
        "def stem_words(text):\n",
        "    \"\"\"\n",
        "    Function to stem words, so all forms of a word is treated in the same way \n",
        "    \"\"\"\n",
        "    try:\n",
        "        text = [stemmer.stem(word) for word in text]\n",
        "        text = [word for word in text if len(word) > 1] #filtering 1 and 2 letter words out\n",
        "    except IndexError:\n",
        "        pass\n",
        "    return text\n",
        "\n",
        "#Option2\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def lemmatize_words(text):\n",
        "    \"\"\"\n",
        "    Function to lemmatize words.\n",
        "    \"\"\"\n",
        "    text = [lemmatizer.lemmatize(word) for word in text]\n",
        "    text = [word for word in text if len(word) > 2] #filtering 1 and 2 letter words out\n",
        "    return text\n",
        "\n",
        "def apply_corrector_and_lemmatizer(text):\n",
        "    \"\"\"\n",
        "    This function applies all the functions above \n",
        "    \"\"\" \n",
        "    return lemmatize_words(correctorForAll(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYuCvbaNHcCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Preprocess IV\n",
        "t7 = time.time()\n",
        "df['tokenized'] = df['tokenized'].apply(stem_words)\n",
        "t8 = time.time()\n",
        "print(\"Time to stem words for \", len(df), \" questions took\", (t8-t7)/60, \"min\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5j_2vVwP88Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dropping the words with little length out\n",
        "t9 = time.time()\n",
        "df['quest_len'] = df['tokenized'].apply(lambda x: len(x))\n",
        "MIN_TOKEN_NUMBER = 9\n",
        "df = df[df['quest_len'] > MIN_TOKEN_NUMBER]\n",
        "t10 = time.time()\n",
        "print(\"Time to drop out the questions with few words took \", (t10-t9)/60, \"min\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr1VB7TbgAsZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kcT_r5V0vDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def csv_formater(line):\n",
        "    \"\"\"\n",
        "    Function to convrt an array into a string by putting comma between words.\n",
        "    \"\"\"\n",
        "    strr = \"\"\n",
        "    for word in line:\n",
        "        strr = strr + word + \",\"\n",
        "    return strr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN4BsgLYIfH1",
        "colab_type": "code",
        "outputId": "1ac26c42-c820-414d-b52b-d5cf20877a7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t11 = time.time()\n",
        "df['words'] = df['tokenized'].apply(csv_formater)\n",
        "t12 = time.time()\n",
        "print(\"Time to make the file ready to store took \", (t12-t11)/60, \"min\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time to make the file ready to store took  0.019699708620707194 min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvtjXaQgPjOO",
        "colab_type": "code",
        "outputId": "5fd3c0a6-58d4-44d6-9911-dbdce5263a89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "df.head(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>details</th>\n",
              "      <th>quest</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>quest_len</th>\n",
              "      <th>words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1262197</td>\n",
              "      <td>i upgraded to my account but form is still sho...</td>\n",
              "      <td>i used jot form from      to      and then we...</td>\n",
              "      <td>i upgraded to my account but form is still sho...</td>\n",
              "      <td>[upgrad, account, form, still, show, quota, er...</td>\n",
              "      <td>29</td>\n",
              "      <td>upgrad,account,form,still,show,quota,error,mes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>180811</td>\n",
              "      <td>why does  captcha  not work first time</td>\n",
              "      <td>whenever i go to my website on which i have a...</td>\n",
              "      <td>why does  captcha  not work first time  whenev...</td>\n",
              "      <td>[captcha, work, first, time, whenev, go, websi...</td>\n",
              "      <td>25</td>\n",
              "      <td>captcha,work,first,time,whenev,go,websit,form,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>147439</td>\n",
              "      <td>is it possible to fix this formatting issue</td>\n",
              "      <td>hi    we have successfuly created this  logo ...</td>\n",
              "      <td>is it possible to fix this formatting issue   ...</td>\n",
              "      <td>[possibl, fix, format, issu, successfuli, crea...</td>\n",
              "      <td>20</td>\n",
              "      <td>possibl,fix,format,issu,successfuli,creat,logo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...                                              words\n",
              "0  1262197  ...  upgrad,account,form,still,show,quota,error,mes...\n",
              "1   180811  ...  captcha,work,first,time,whenev,go,websit,form,...\n",
              "2   147439  ...  possibl,fix,format,issu,successfuli,creat,logo...\n",
              "\n",
              "[3 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8AdiuTJh6MM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving the latest verison as csv for practical use in modelling\n",
        "export_csv = df.to_csv ('gdrive/My Drive/summer2019/cleanData.csv', index = None, header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m61kUGydif6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = pd.read_csv('gdrive/My Drive/summer2019/cleanData.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAcsFfgUXyVD",
        "colab_type": "code",
        "outputId": "83387d82-5267-42b9-880f-94ccf46eb29d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "d.head(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>details</th>\n",
              "      <th>quest</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>quest_len</th>\n",
              "      <th>words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1262197</td>\n",
              "      <td>i upgraded to my account but form is still sho...</td>\n",
              "      <td>i used jot form from      to      and then we...</td>\n",
              "      <td>i upgraded to my account but form is still sho...</td>\n",
              "      <td>['upgrad', 'account', 'form', 'still', 'show',...</td>\n",
              "      <td>29</td>\n",
              "      <td>upgrad,account,form,still,show,quota,error,mes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>180811</td>\n",
              "      <td>why does  captcha  not work first time</td>\n",
              "      <td>whenever i go to my website on which i have a...</td>\n",
              "      <td>why does  captcha  not work first time  whenev...</td>\n",
              "      <td>['captcha', 'work', 'first', 'time', 'whenev',...</td>\n",
              "      <td>25</td>\n",
              "      <td>captcha,work,first,time,whenev,go,websit,form,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>147439</td>\n",
              "      <td>is it possible to fix this formatting issue</td>\n",
              "      <td>hi    we have successfuly created this  logo ...</td>\n",
              "      <td>is it possible to fix this formatting issue   ...</td>\n",
              "      <td>['possibl', 'fix', 'format', 'issu', 'successf...</td>\n",
              "      <td>20</td>\n",
              "      <td>possibl,fix,format,issu,successfuli,creat,logo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...                                              words\n",
              "0  1262197  ...  upgrad,account,form,still,show,quota,error,mes...\n",
              "1   180811  ...  captcha,work,first,time,whenev,go,websit,form,...\n",
              "2   147439  ...  possibl,fix,format,issu,successfuli,creat,logo...\n",
              "\n",
              "[3 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    }
  ]
}