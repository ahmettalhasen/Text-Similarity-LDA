{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "projectSupportWork.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmettalhasen/Text-Similarity-LDA/blob/master/projectSupportWork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5_2dU4hQEU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk import FreqDist\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from scipy.stats import entropy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style(\"darkgrid\")\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "import gensim\n",
        "from gensim.models import LdaModel\n",
        "from gensim import models, corpora, similarities\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "!pip install pyLDAvis #Visualize the topics of LDA model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c4EkSx3P5Zb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Importing the dataset\n",
        "df = pd.read_csv('gdrive/My Drive/summer2019/cleanData.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5mRMvTsQDf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['tokenized'] = [[word for word in line.split(',') if len(word) > 1] for line in df['words']]\n",
        "df = df.drop(columns = ['question', 'details', 'quest_len', 'words'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pVtKGfc7hpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp80cjN0zCAV",
        "colab_type": "code",
        "outputId": "dc4edc3d-215f-45eb-e581-069919b02738",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Using FreqDist\n",
        "words = [word for row in list(df.tokenized) for word in row]\n",
        "\n",
        "freqDist = FreqDist(words)\n",
        "print(\"Number of distinct words is, \", len(freqDist))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of distinct words is,  90064\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwh-JO3yzGyl",
        "colab_type": "code",
        "outputId": "5b327ff6-78d6-440d-cccb-dc1cff93ba4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Top 30 used words\n",
        "k = 10000\n",
        "top_k_words = freqDist.most_common(k)\n",
        "top_k_words[:500]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('form', 374032),\n",
              " ('email', 83537),\n",
              " ('use', 72146),\n",
              " ('field', 64265),\n",
              " ('submiss', 57746),\n",
              " ('work', 53875),\n",
              " ('account', 50874),\n",
              " ('get', 49285),\n",
              " ('page', 47885),\n",
              " ('creat', 44741),\n",
              " ('need', 44534),\n",
              " ('jotform', 44295),\n",
              " ('submit', 41911),\n",
              " ('like', 41874),\n",
              " ('one', 41462),\n",
              " ('tri', 40205),\n",
              " ('help', 39310),\n",
              " ('chang', 38200),\n",
              " ('want', 37667),\n",
              " ('show', 35691),\n",
              " ('option', 34397),\n",
              " ('user', 32678),\n",
              " ('way', 31950),\n",
              " ('payment', 30474),\n",
              " ('see', 29853),\n",
              " ('receiv', 28185),\n",
              " ('link', 27770),\n",
              " ('button', 27497),\n",
              " ('set', 27434),\n",
              " ('make', 26594),\n",
              " ('time', 26572),\n",
              " ('text', 26165),\n",
              " ('question', 25992),\n",
              " ('name', 25691),\n",
              " ('possibl', 24978),\n",
              " ('data', 23397),\n",
              " ('websit', 23324),\n",
              " ('custom', 23117),\n",
              " ('address', 22705),\n",
              " ('add', 22027),\n",
              " ('select', 21711),\n",
              " ('new', 21702),\n",
              " ('fill', 21618),\n",
              " ('send', 21358),\n",
              " ('file', 21152),\n",
              " ('upload', 21147),\n",
              " ('know', 20994),\n",
              " ('pdf', 20896),\n",
              " ('error', 20673),\n",
              " ('look', 20587),\n",
              " ('problem', 20322),\n",
              " ('code', 19843),\n",
              " ('inform', 19294),\n",
              " ('integr', 19227),\n",
              " ('paypal', 18733),\n",
              " ('number', 18130),\n",
              " ('widget', 18086),\n",
              " ('condit', 17848),\n",
              " ('abl', 17838),\n",
              " ('also', 17812),\n",
              " ('box', 17737),\n",
              " ('edit', 17463),\n",
              " ('site', 17409),\n",
              " ('click', 17021),\n",
              " ('messag', 16800),\n",
              " ('issu', 16566),\n",
              " ('notif', 16513),\n",
              " ('list', 15865),\n",
              " ('say', 15811),\n",
              " ('differ', 15710),\n",
              " ('check', 14991),\n",
              " ('complet', 14973),\n",
              " ('date', 14776),\n",
              " ('still', 14657),\n",
              " ('client', 14531),\n",
              " ('imag', 14361),\n",
              " ('order', 14305),\n",
              " ('back', 14232),\n",
              " ('appear', 13764),\n",
              " ('valu', 13623),\n",
              " ('googl', 13445),\n",
              " ('test', 13417),\n",
              " ('peopl', 13276),\n",
              " ('allow', 13200),\n",
              " ('save', 13161),\n",
              " ('seem', 13000),\n",
              " ('howev', 12955),\n",
              " ('multipl', 12712),\n",
              " ('anoth', 12666),\n",
              " ('first', 12639),\n",
              " ('sent', 12567),\n",
              " ('input', 12533),\n",
              " ('answer', 12333),\n",
              " ('display', 12132),\n",
              " ('url', 12085),\n",
              " ('attach', 11947),\n",
              " ('two', 11913),\n",
              " ('limit', 11893),\n",
              " ('respons', 11825),\n",
              " ('fix', 11641),\n",
              " ('month', 11426),\n",
              " ('enter', 11348),\n",
              " ('product', 11192),\n",
              " ('view', 11168),\n",
              " ('happen', 11167),\n",
              " ('card', 11132),\n",
              " ('requir', 11112),\n",
              " ('delet', 11106),\n",
              " ('type', 11091),\n",
              " ('access', 10962),\n",
              " ('free', 10487),\n",
              " ('contact', 10481),\n",
              " ('find', 10310),\n",
              " ('regard', 10282),\n",
              " ('come', 10131),\n",
              " ('mani', 10126),\n",
              " ('updat', 10120),\n",
              " ('current', 10114),\n",
              " ('mail', 10070),\n",
              " ('person', 9992),\n",
              " ('upgrad', 9965),\n",
              " ('report', 9861),\n",
              " ('servic', 9765),\n",
              " ('line', 9692),\n",
              " ('applic', 9633),\n",
              " ('someon', 9613),\n",
              " ('let', 9593),\n",
              " ('calcul', 9564),\n",
              " ('exampl', 9455),\n",
              " ('download', 9296),\n",
              " ('remov', 9220),\n",
              " ('take', 9212),\n",
              " ('disabl', 9106),\n",
              " ('someth', 9051),\n",
              " ('size', 9041),\n",
              " ('day', 8990),\n",
              " ('right', 8946),\n",
              " ('plan', 8833),\n",
              " ('amp', 8726),\n",
              " ('open', 8724),\n",
              " ('even', 8686),\n",
              " ('put', 8675),\n",
              " ('last', 8658),\n",
              " ('pay', 8549),\n",
              " ('label', 8521),\n",
              " ('request', 8444),\n",
              " ('sign', 8416),\n",
              " ('follow', 8406),\n",
              " ('next', 8155),\n",
              " ('includ', 8086),\n",
              " ('embed', 8036),\n",
              " ('total', 8027),\n",
              " ('registr', 8025),\n",
              " ('made', 8014),\n",
              " ('ask', 7929),\n",
              " ('item', 7899),\n",
              " ('keep', 7884),\n",
              " ('mobil', 7863),\n",
              " ('provid', 7730),\n",
              " ('space', 7672),\n",
              " ('sure', 7636),\n",
              " ('password', 7625),\n",
              " ('price', 7624),\n",
              " ('copi', 7572),\n",
              " ('width', 7524),\n",
              " ('format', 7385),\n",
              " ('support', 7357),\n",
              " ('jot', 7344),\n",
              " ('secur', 7339),\n",
              " ('font', 7332),\n",
              " ('emb', 7235),\n",
              " ('automat', 7174),\n",
              " ('print', 7160),\n",
              " ('base', 7156),\n",
              " ('phone', 7119),\n",
              " ('end', 7093),\n",
              " ('subscript', 7039),\n",
              " ('import', 7019),\n",
              " ('log', 7011),\n",
              " ('color', 7003),\n",
              " ('advis', 6980),\n",
              " ('give', 6971),\n",
              " ('class', 6948),\n",
              " ('credit', 6927),\n",
              " ('year', 6900),\n",
              " ('version', 6859),\n",
              " ('section', 6840),\n",
              " ('info', 6788),\n",
              " ('screen', 6782),\n",
              " ('start', 6755),\n",
              " ('drop', 6752),\n",
              " ('preview', 6709),\n",
              " ('load', 6661),\n",
              " ('css', 6522),\n",
              " ('column', 6513),\n",
              " ('fine', 6510),\n",
              " ('style', 6478),\n",
              " ('via', 6456),\n",
              " ('auto', 6421),\n",
              " ('correct', 6388),\n",
              " ('much', 6373),\n",
              " ('featur', 6336),\n",
              " ('avail', 6314),\n",
              " ('design', 6309),\n",
              " ('instead', 6307),\n",
              " ('entri', 6291),\n",
              " ('spreadsheet', 6260),\n",
              " ('advanc', 6191),\n",
              " ('sever', 6185),\n",
              " ('found', 6184),\n",
              " ('wrong', 6179),\n",
              " ('browser', 6145),\n",
              " ('alreadi', 6143),\n",
              " ('process', 6111),\n",
              " ('unabl', 6091),\n",
              " ('web', 6086),\n",
              " ('well', 6058),\n",
              " ('onlin', 6056),\n",
              " ('miss', 6008),\n",
              " ('result', 5997),\n",
              " ('login', 5985),\n",
              " ('tell', 5924),\n",
              " ('function', 5870),\n",
              " ('choos', 5869),\n",
              " ('today', 5853),\n",
              " ('html', 5816),\n",
              " ('survey', 5800),\n",
              " ('detail', 5777),\n",
              " ('templat', 5760),\n",
              " ('amount', 5748),\n",
              " ('best', 5745),\n",
              " ('etc', 5732),\n",
              " ('compani', 5725),\n",
              " ('background', 5682),\n",
              " ('post', 5666),\n",
              " ('top', 5655),\n",
              " ('everi', 5642),\n",
              " ('per', 5608),\n",
              " ('may', 5591),\n",
              " ('document', 5558),\n",
              " ('confirm', 5542),\n",
              " ('good', 5522),\n",
              " ('sinc', 5506),\n",
              " ('blank', 5499),\n",
              " ('left', 5394),\n",
              " ('noth', 5374),\n",
              " ('excel', 5318),\n",
              " ('stop', 5295),\n",
              " ('specif', 5270),\n",
              " ('ifram', 5261),\n",
              " ('realli', 5261),\n",
              " ('system', 5235),\n",
              " ('second', 5219),\n",
              " ('tabl', 5204),\n",
              " ('app', 5139),\n",
              " ('place', 5138),\n",
              " ('think', 5137),\n",
              " ('done', 5094),\n",
              " ('folder', 5091),\n",
              " ('move', 5090),\n",
              " ('great', 5072),\n",
              " ('event', 5070),\n",
              " ('appreci', 5019),\n",
              " ('past', 5009),\n",
              " ('com', 4971),\n",
              " ('purchas', 4969),\n",
              " ('longer', 4964),\n",
              " ('wonder', 4940),\n",
              " ('team', 4925),\n",
              " ('got', 4918),\n",
              " ('thing', 4907),\n",
              " ('collect', 4893),\n",
              " ('gener', 4821),\n",
              " ('part', 4805),\n",
              " ('hide', 4794),\n",
              " ('choic', 4771),\n",
              " ('hidden', 4745),\n",
              " ('busi', 4737),\n",
              " ('within', 4692),\n",
              " ('long', 4681),\n",
              " ('sheet', 4670),\n",
              " ('script', 4664),\n",
              " ('dropdown', 4654),\n",
              " ('respond', 4646),\n",
              " ('screenshot', 4629),\n",
              " ('bottom', 4628),\n",
              " ('call', 4620),\n",
              " ('hope', 4593),\n",
              " ('paid', 4574),\n",
              " ('tab', 4573),\n",
              " ('reason', 4537),\n",
              " ('usernam', 4536),\n",
              " ('read', 4516),\n",
              " ('sub', 4506),\n",
              " ('old', 4490),\n",
              " ('correctli', 4477),\n",
              " ('window', 4441),\n",
              " ('anyth', 4437),\n",
              " ('regist', 4437),\n",
              " ('charg', 4424),\n",
              " ('notic', 4419),\n",
              " ('cancel', 4418),\n",
              " ('radio', 4401),\n",
              " ('repli', 4382),\n",
              " ('share', 4357),\n",
              " ('actual', 4355),\n",
              " ('clone', 4332),\n",
              " ('week', 4332),\n",
              " ('facebook', 4320),\n",
              " ('run', 4314),\n",
              " ('suspend', 4311),\n",
              " ('build', 4307),\n",
              " ('tool', 4307),\n",
              " ('dropbox', 4300),\n",
              " ('idea', 4287),\n",
              " ('server', 4252),\n",
              " ('connect', 4208),\n",
              " ('full', 4117),\n",
              " ('locat', 4107),\n",
              " ('figur', 4105),\n",
              " ('titl', 4102),\n",
              " ('popul', 4089),\n",
              " ('continu', 4071),\n",
              " ('suggest', 4054),\n",
              " ('area', 4050),\n",
              " ('chrome', 4043),\n",
              " ('reset', 4037),\n",
              " ('lot', 4017),\n",
              " ('either', 4005),\n",
              " ('everyth', 4004),\n",
              " ('exist', 3981),\n",
              " ('state', 3974),\n",
              " ('checkbox', 3940),\n",
              " ('guy', 3919),\n",
              " ('reach', 3909),\n",
              " ('default', 3892),\n",
              " ('addit', 3891),\n",
              " ('clear', 3887),\n",
              " ('separ', 3879),\n",
              " ('properli', 3857),\n",
              " ('recent', 3816),\n",
              " ('photo', 3815),\n",
              " ('span', 3780),\n",
              " ('assist', 3771),\n",
              " ('solut', 3761),\n",
              " ('signatur', 3751),\n",
              " ('configur', 3747),\n",
              " ('later', 3734),\n",
              " ('forward', 3732),\n",
              " ('monthli', 3721),\n",
              " ('mean', 3720),\n",
              " ('word', 3703),\n",
              " ('certain', 3701),\n",
              " ('recipi', 3691),\n",
              " ('autorespond', 3687),\n",
              " ('redirect', 3675),\n",
              " ('fals', 3653),\n",
              " ('sourc', 3639),\n",
              " ('return', 3613),\n",
              " ('direct', 3579),\n",
              " ('block', 3544),\n",
              " ('manag', 3536),\n",
              " ('accept', 3524),\n",
              " ('pass', 3518),\n",
              " ('offer', 3517),\n",
              " ('insert', 3514),\n",
              " ('height', 3507),\n",
              " ('kind', 3500),\n",
              " ('header', 3494),\n",
              " ('stripe', 3491),\n",
              " ('singl', 3491),\n",
              " ('previou', 3490),\n",
              " ('understand', 3442),\n",
              " ('origin', 3433),\n",
              " ('align', 3412),\n",
              " ('never', 3404),\n",
              " ('hit', 3394),\n",
              " ('asap', 3393),\n",
              " ('none', 3393),\n",
              " ('though', 3391),\n",
              " ('activ', 3387),\n",
              " ('wait', 3351),\n",
              " ('dear', 3337),\n",
              " ('transfer', 3311),\n",
              " ('publish', 3309),\n",
              " ('step', 3305),\n",
              " ('setup', 3296),\n",
              " ('drive', 3292),\n",
              " ('content', 3280),\n",
              " ('case', 3278),\n",
              " ('enabl', 3273),\n",
              " ('row', 3270),\n",
              " ('export', 3265),\n",
              " ('pictur', 3263),\n",
              " ('hour', 3261),\n",
              " ('api', 3227),\n",
              " ('yet', 3216),\n",
              " ('author', 3201),\n",
              " ('valid', 3183),\n",
              " ('contain', 3140),\n",
              " ('disappear', 3135),\n",
              " ('break', 3135),\n",
              " ('goe', 3134),\n",
              " ('around', 3127),\n",
              " ('side', 3125),\n",
              " ('live', 3124),\n",
              " ('shown', 3121),\n",
              " ('quota', 3104),\n",
              " ('element', 3090),\n",
              " ('non', 3089),\n",
              " ('fail', 3085),\n",
              " ('mode', 3082),\n",
              " ('logic', 3075),\n",
              " ('ssl', 3072),\n",
              " ('record', 3066),\n",
              " ('wordpress', 3060),\n",
              " ('appli', 3058),\n",
              " ('success', 3054),\n",
              " ('went', 3036),\n",
              " ('premium', 3027),\n",
              " ('devic', 2996),\n",
              " ('encrypt', 2974),\n",
              " ('three', 2973),\n",
              " ('editor', 2963),\n",
              " ('key', 2958),\n",
              " ('net', 2954),\n",
              " ('uniqu', 2938),\n",
              " ('method', 2928),\n",
              " ('bill', 2920),\n",
              " ('caus', 2919),\n",
              " ('els', 2917),\n",
              " ('menu', 2895),\n",
              " ('love', 2894),\n",
              " ('firefox', 2884),\n",
              " ('builder', 2881),\n",
              " ('simpl', 2881),\n",
              " ('scroll', 2858),\n",
              " ('store', 2855),\n",
              " ('white', 2854),\n",
              " ('forum', 2845),\n",
              " ('bronz', 2836),\n",
              " ('point', 2835),\n",
              " ('ago', 2835),\n",
              " ('languag', 2821),\n",
              " ('border', 2819),\n",
              " ('resolv', 2814),\n",
              " ('comput', 2794),\n",
              " ('book', 2786),\n",
              " ('term', 2783),\n",
              " ('alway', 2782),\n",
              " ('quantiti', 2778),\n",
              " ('member', 2777),\n",
              " ('div', 2769),\n",
              " ('databas', 2767),\n",
              " ('duplic', 2736),\n",
              " ('individu', 2731),\n",
              " ('close', 2726),\n",
              " ('must', 2715),\n",
              " ('rather', 2693),\n",
              " ('due', 2691),\n",
              " ('pop', 2665),\n",
              " ('thought', 2642),\n",
              " ('soon', 2634),\n",
              " ('troubl', 2606),\n",
              " ('basic', 2596),\n",
              " ('program', 2581),\n",
              " ('refer', 2577),\n",
              " ('empti', 2576),\n",
              " ('downgrad', 2545),\n",
              " ('abil', 2535),\n",
              " ('group', 2491),\n",
              " ('donat', 2479),\n",
              " ('logo', 2478),\n",
              " ('matrix', 2473),\n",
              " ('attempt', 2473),\n",
              " ('coupl', 2468),\n",
              " ('javascript', 2467),\n",
              " ('ticket', 2464),\n",
              " ('instruct', 2451),\n",
              " ('squar', 2438),\n",
              " ('search', 2434),\n",
              " ('visibl', 2432),\n",
              " ('morn', 2430),\n",
              " ('discount', 2423),\n",
              " ('yesterday', 2417),\n",
              " ('translat', 2409),\n",
              " ('theme', 2404),\n",
              " ('student', 2385),\n",
              " ('iphon', 2383),\n",
              " ('entir', 2380),\n",
              " ('turn', 2379),\n",
              " ('fee', 2379),\n",
              " ('directli', 2375),\n",
              " ('control', 2373),\n",
              " ('anyon', 2365),\n",
              " ('might', 2362),\n",
              " ('manual', 2349),\n",
              " ('track', 2283),\n",
              " ('pre', 2276),\n",
              " ('layout', 2271)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu2Wm1pYzIyQ",
        "colab_type": "code",
        "outputId": "89116311-6b62-40a1-f895-348ad085449b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Bottom 30 used words\n",
        "k = 5000\n",
        "top_k_words = freqDist.most_common(k)\n",
        "top_k_words[-100:]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('beliz', 28),\n",
              " ('benin', 28),\n",
              " ('bermuda', 28),\n",
              " ('burkina', 28),\n",
              " ('faso', 28),\n",
              " ('burundi', 28),\n",
              " ('cayman', 28),\n",
              " ('coco', 28),\n",
              " ('keel', 28),\n",
              " ('comoro', 28),\n",
              " ('djibouti', 28),\n",
              " ('dominica', 28),\n",
              " ('equatori', 28),\n",
              " ('eritrea', 28),\n",
              " ('fiji', 28),\n",
              " ('polynesia', 28),\n",
              " ('greenland', 28),\n",
              " ('grenada', 28),\n",
              " ('guernsey', 28),\n",
              " ('bissau', 28),\n",
              " ('kiribati', 28),\n",
              " ('kosovo', 28),\n",
              " ('kyrgyzstan', 28),\n",
              " ('latvia', 28),\n",
              " ('lesotho', 28),\n",
              " ('libya', 28),\n",
              " ('liechtenstein', 28),\n",
              " ('madagascar', 28),\n",
              " ('malta', 28),\n",
              " ('mauritiu', 28),\n",
              " ('mayott', 28),\n",
              " ('micronesia', 28),\n",
              " ('moldova', 28),\n",
              " ('montenegro', 28),\n",
              " ('morocco', 28),\n",
              " ('mozambiqu', 28),\n",
              " ('nagorno', 28),\n",
              " ('karabakh', 28),\n",
              " ('nauru', 28),\n",
              " ('antil', 28),\n",
              " ('caledonia', 28),\n",
              " ('niue', 28),\n",
              " ('paraguay', 28),\n",
              " ('pitcairn', 28),\n",
              " ('emir', 28),\n",
              " ('pump', 28),\n",
              " ('staf', 28),\n",
              " ('erica', 28),\n",
              " ('incas', 28),\n",
              " ('stabil', 28),\n",
              " ('cosmet', 28),\n",
              " ('jona', 28),\n",
              " ('hop', 28),\n",
              " ('templet', 28),\n",
              " ('dale', 28),\n",
              " ('loggin', 28),\n",
              " ('intervent', 28),\n",
              " ('ahv', 28),\n",
              " ('dilemma', 28),\n",
              " ('marku', 28),\n",
              " ('brasil', 28),\n",
              " ('giant', 28),\n",
              " ('eval', 28),\n",
              " ('fool', 28),\n",
              " ('veterinari', 28),\n",
              " ('vinc', 28),\n",
              " ('deeper', 28),\n",
              " ('urg', 28),\n",
              " ('subproduct', 28),\n",
              " ('repsons', 28),\n",
              " ('aac', 28),\n",
              " ('wright', 28),\n",
              " ('whith', 28),\n",
              " ('fleet', 28),\n",
              " ('cuenta', 28),\n",
              " ('veteran', 28),\n",
              " ('conect', 28),\n",
              " ('prolifer', 28),\n",
              " ('quest', 28),\n",
              " ('webservic', 28),\n",
              " ('heat', 28),\n",
              " ('maggi', 28),\n",
              " ('pish', 28),\n",
              " ('nan', 28),\n",
              " ('eve', 28),\n",
              " ('cameron', 28),\n",
              " ('condition', 28),\n",
              " ('whitepap', 28),\n",
              " ('xero', 28),\n",
              " ('dice', 28),\n",
              " ('irrelev', 28),\n",
              " ('ineffici', 28),\n",
              " ('peso', 28),\n",
              " ('tmp', 28),\n",
              " ('pieter', 28),\n",
              " ('messeg', 28),\n",
              " ('lectur', 28),\n",
              " ('breakout', 28),\n",
              " ('caland', 28),\n",
              " ('annot', 28)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iEZHCFBzLn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_k_words,_ = zip(*freqDist.most_common(k))\n",
        "top_k_words = set(top_k_words)\n",
        "#Throws all the rare used words away\n",
        "def keep_top_k_words(text):\n",
        "  \n",
        "    return [word for word in text if word in top_k_words]\n",
        "\n",
        "df['tokenized'] = df['tokenized'].apply(keep_top_k_words)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCaLkwmu09I3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz9u_NRzzZa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['quest_len'] = df['tokenized'].apply(lambda x: len(x))\n",
        "quest_lengths = list(df['quest_len'])\n",
        "\n",
        "MIN_TOKEN_NUMBER = 4\n",
        "\n",
        "# Histogram Plot\n",
        "fig, ax = plt.subplots(figsize=(16,8));\n",
        "n, bins, patches = ax.hist(quest_lengths, 750)\n",
        "ax.set_xlabel('Question Length (tokens)', fontsize=20)\n",
        "ax.set_ylabel('Count', fontsize=20)\n",
        "ax.grid()\n",
        "plt.xlim(0,150)\n",
        "ax.grid()\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "df = df[df['quest_len'] > MIN_TOKEN_NUMBER]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi9vn2K6MqIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-gPT1JpzkN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# question length\n",
        "df.drop(labels='quest_len', axis=1, inplace=True)\n",
        "\n",
        "print(\"length of list:\",len(quest_lengths),\n",
        "      \"\\naverage question length\", np.average(quest_lengths),\n",
        "      \"\\nminimum question length\", min(quest_lengths),\n",
        "      \"\\nmaximum question length\", max(quest_lengths))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4snabJLy1Iq7",
        "colab_type": "code",
        "outputId": "9b1a692f-1464-4b19-deeb-b2fee0717bdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        }
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABHgAAAI4CAYAAAARel4VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_9t_gopejeS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Splitting into train and test sets.\n",
        "chosen = np.random.rand(len(df)) < 0.9999\n",
        "train_set = df[chosen]\n",
        "test_set = df[~chosen]\n",
        "train_set.reset_index(drop=True,inplace=True)\n",
        "test_set.reset_index(drop=True,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW63Wv988RCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_set\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOhmLYg-f-G7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating corpus an dictionary\n",
        "\n",
        "dictionary = corpora.Dictionary(data['tokenized'])\n",
        "corpus = [dictionary.doc2bow(doc) for doc in data['tokenized']]\n",
        "\n",
        "def train_lda(cluster_size, num_passes, data):\n",
        "    \"\"\"\n",
        "    This function trains the LDA model\n",
        "    We setup parameters like number of topics, number of passes to train the model \n",
        "    and train set\n",
        "    \"\"\"\n",
        "    \n",
        "    time01 = time.time()\n",
        "    # low alpha means each document is only represented by a small number of topics, and vice versa\n",
        "    # low eta means each topic is only represented by a small number of words, and vice versa\n",
        "    lda = LdaModel(corpus=corpus, num_topics=cluster_size, id2word=dictionary,\n",
        "                   alpha=1e-2, eta=0.5e-2, minimum_probability=0.0, passes=num_passes)\n",
        "    time02 = time.time()\n",
        "    print(\"Time to train LDA model on \", len(df), \"questions: \", (time02-time01)/60, \"min\")\n",
        "    return lda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1Kc0p8s5d-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Alternatif way of LDA\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saVUH30eOf9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", category=PendingDeprecationWarning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-9wXuH6m4FL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training LDA Model and displaying the characteristic words\n",
        "num_clusters = 700\n",
        "lda = train_lda(num_clusters, 15, train_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkrJiG96b2hM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "topic_highlights = [('*---------------------------', lda.show_topic(topicid=i, topn=20)) for i in range(num_clusters) ]\n",
        "topic_highlights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGLt9l5HCw_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Evaluation of the number of the topics\n",
        "import pyLDAvis.gensim\n",
        "\n",
        "LDAvis_prepared = pyLDAvis.gensim.prepare(lda, corpus, dictionary, mds='mmds')\n",
        "pyLDAvis.display(LDAvis_prepared)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k89u78hqjxv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Topic Distribution\n",
        "\n",
        "def calculate_all_documents_distribution(ldaModel):\n",
        "    \"\"\"\n",
        "    This function calculates the topic distributions of the all quesitons in the train set\n",
        "    \"\"\"\n",
        "    docs_topic_dist = np.array([[tup[1] for tup in lst] for lst in ldaModel[corpus]])\n",
        "    return docs_topic_dist\n",
        "\n",
        "\n",
        "docs_topic_dist = calculate_all_documents_distribution(lda)\n",
        "print(\"Shape of the matrix is \", docs_topic_dist.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9S79E9RjBAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Getting a Question From the Test Set\n",
        "def random_question_picker(test_set):\n",
        "    \"\"\"\n",
        "    This function picks a random question from test set \n",
        "    \"\"\"\n",
        "    random_article_index = np.random.randint(len(test_set))\n",
        "    return random_article_index \n",
        "  \n",
        "def calculate_new_document_distribution(test_set, random_article_index):\n",
        "    \"\"\"\n",
        "    This function calculates the topic distributions of the given question\n",
        "    \"\"\"\n",
        "    new_bow = dictionary.doc2bow(test_set.tokenized[random_article_index])\n",
        "    print(test_set.quest[random_article_index])\n",
        "    new_doc_distribution = np.array([tup[1] for tup in lda.get_document_topics(bow=new_bow)])\n",
        "    return new_doc_distribution"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D8YeZr1j4b_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def jensen_shannon(query, matrix):\n",
        "    \"\"\"\n",
        "    This function implements a Jensen-Shannon similarity\n",
        "    between the input query (an LDA topic distribution for a document)\n",
        "    and the entire corpus of topic distributions.\n",
        "    It returns an array of length M where M is the number of documents in the corpus\n",
        "    \"\"\"\n",
        "    # lets keep with the p,q notation above\n",
        "    p = query[None,:].T # take transpose\n",
        "    q = matrix.T # transpose matrix\n",
        "    m = 0.5*(p + q)\n",
        "    return np.sqrt(0.5*(entropy(p,m) + entropy(q,m)))\n",
        "  \n",
        "def cosine_dist(query, matrix):\n",
        "    \"\"\"\n",
        "    This function implements cosine similarity\n",
        "    between the input query (an LDA topic distribution for a document)\n",
        "    and the entire corpus of topic distributions.\n",
        "    It returns an array of length M where M is the number of documents in the corpus\n",
        "    \"\"\"\n",
        "    return [gensim.matutils.cossim(query, x) for x in matrix]\n",
        "  \n",
        "\n",
        "def get_most_similar_documents(query,matrix,k=10):\n",
        "    \"\"\"\n",
        "    This function implements the Jensen-Shannon distance above\n",
        "    and retruns the top k indices of the smallest jensen shannon distances\n",
        "    \"\"\"\n",
        "    sims = jensen_shannon(query,matrix) # list of jensen shannon distances\n",
        "    return sims.argsort()[:k] # the top k positional index of the smallest Jensen Shannon distances"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmaB2bwPj5Qz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retrieve_similar_questions(test_set, train_set, random_article_index, docs_topic_dist):\n",
        "    \"\"\"\n",
        "    This functions retrives similar questions from the train set\n",
        "    \"\"\"\n",
        "    new_doc_distribution = calculate_new_document_distribution(test_set, random_article_index)\n",
        "    most_sim_ids = get_most_similar_documents(new_doc_distribution,docs_topic_dist)\n",
        "    most_similar_df = train_set[train_set.index.isin(most_sim_ids)]\n",
        "    questList = list(most_similar_df['quest'])\n",
        "    idList = list(most_similar_df['id'])\n",
        "    return questList,idList"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72hMsve4oxbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Giving it a try\n",
        "def try_many(number):\n",
        "    for i in range(number):\n",
        "      print(\"The Question Number \", i)\n",
        "      qList,idList = retrieve_similar_questions(test_set, train_set, i, docs_topic_dist)\n",
        "      a = [print(\"Similar--> \", el) for el in qList ]\n",
        "\n",
        "try_many(28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGagfFxNpUjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_recommendation_csv(train_set, test_set):\n",
        "    \"\"\"\n",
        "    this function finds recommendation for multiple test data and saving them in a csv file\n",
        "    \"\"\"\n",
        "    dataframe = pd.DataFrame(columns=['id', 'question', 'recommendations', 'idsOfRecommendations'])\n",
        "    \n",
        "    for i in range(len(test_set)):\n",
        "      question_index = i\n",
        "      qList, idList = retrieve_similar_questions(test_set, train_set, question_index)\n",
        "      text = \"\"\n",
        "      ids = \"\"\n",
        "      \n",
        "      for j in range(len(qList)):\n",
        "        text = text + \"|\" + qList[j]\n",
        "        ids = ids + \",\" + str(idList[j])\n",
        "        \n",
        "      dataframe.loc[i] = [str(test_set['id'][i]), test_set['quest'][i], text, ids]     \n",
        "      \n",
        "    ## Saving the latest verison as csv for practical use\n",
        "    export_csv = dataframe.to_csv('gdrive/My Drive/summer2019/testRecommendations.csv', index = None, header=True)\n",
        "    print(\"testRecommendations.csv is created.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHeVTa59xKsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_recommendation_csv(train_set, test_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZGzlwHZ7vDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = pd.read_csv('gdrive/My Drive/summer2019/testRecommendations.csv')\n",
        "d.recommendations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4EuLyRf2tlo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ques = []\n",
        "for row in train_set['tokenized']:\n",
        "  row = list(dict.fromkeys(row))\n",
        "  s = \"\"\n",
        "  for x in row:\n",
        "    s = s + \" \" + x\n",
        "  s = s.strip()\n",
        "  ques.append(s)\n",
        "  \n",
        "ques"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgKpz6an2dHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################\n",
        "\n",
        "\n",
        "from nltk import ngrams\n",
        "from scipy.spatial import distance\n",
        "\n",
        "def similar_question_jaccard(question, train_set):\n",
        "    \"\"\"\n",
        "    This function to finds and returns similar questions among train set \n",
        "    by Jaccard Distance\n",
        "    \"\"\"\n",
        "    questions=[]\n",
        "    for train_quest in train_set:\n",
        "        dist=distance.jaccard(set(ngrams(question,n=1)),set(ngrams(train_quest,n=1)))\n",
        "        if(dist<.1):\n",
        "            questions.append(train_quest)\n",
        "    return questions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md7gl1jq0J1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quesTest = ques[:15]\n",
        "quesTrain = ques[15:]\n",
        "\n",
        "for q in quesTest:\n",
        "  print(\"The Question --------> \", q)\n",
        "  qs = similar_question_jaccard(q,quesTrain)\n",
        "  v = [print(\"Similar ---> \", s) for s in qs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_VX125XNnxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "randNum = random_question_picker(test_set)\n",
        "test_set.quest[randNum]\n",
        "qs = similar_question_jaccard(test_set.tokenized[randNum])\n",
        "qs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5TtBwIdCDU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#word2Vec\n",
        "model = word2vec.Word2Vec(corpus, size=100, window=20, min_count=40, workers=4)\n",
        "#TSNE\n",
        "\n",
        "\n",
        "def tsne_plot(model,title='None'):\n",
        "    \"\"\"\n",
        "    This function creates and TSNE model and plots it\n",
        "    \"\"\"\n",
        "    labels = []\n",
        "    tokens = []\n",
        "\n",
        "    for word in model.wv.vocab:\n",
        "        tokens.append(model[word])\n",
        "        labels.append(word)\n",
        "    \n",
        "    tsne_model = TSNE(perplexity=80, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
        "    new_values = tsne_model.fit_transform(tokens)\n",
        "\n",
        "    x = []\n",
        "    y = []\n",
        "    for value in new_values:\n",
        "        x.append(value[0])\n",
        "        y.append(value[1])\n",
        "        \n",
        "    plt.figure(figsize=(12, 12)) \n",
        "    plt.title(title)\n",
        "    for i in range(len(x)):\n",
        "        plt.scatter(x[i],y[i])\n",
        "        plt.annotate(labels[i],\n",
        "                     xy=(x[i], y[i]),\n",
        "                     xytext=(5, 2),\n",
        "                     textcoords='offset points',\n",
        "                     ha='right',\n",
        "                     va='bottom')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "tsne_plot(lda,'Questions')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSDsjPDsklrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now, We will analyze the goodness of our model based on number of clusters by using coherence value\n",
        "def compute_coherence_values(train_set, stop=100, start=20, step=10):\n",
        "    \"\"\"\n",
        "    Input   : dictionary : Gensim dictionary\n",
        "              corpus : Gensim corpus\n",
        "              texts : List of input texts\n",
        "              stop : Max num of topics\n",
        "    purpose : Compute c_v coherence for various number of topics\n",
        "    Output  : model_list : List of LSA topic models\n",
        "              coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
        "    \"\"\"\n",
        "    timeCohSt = time.time()\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    \n",
        "    for num_topics in range(start, stop, step):\n",
        "        # generate LDA model\n",
        "        timeTrain01 = time.time()\n",
        "        model = train_lda(num_topics, 5, train_set)\n",
        "        model_list.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=train_set, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "        timeTrain02 = time.time()\n",
        "        print(\"LDA Model with \", num_topics, \" topics trained in \", \n",
        "              (timeTrain02-timeTrain01)/60, \" min. The coherence value which is \",\n",
        "              coherencemodel.get_coherence(), \" added!\") \n",
        "    \n",
        "    timeCohEnd = time.time()\n",
        "    print(\"Time to train all LDA models and calculating coherence took  \", (timeCohEnd-timeCohSt)/60, \"min\")\n",
        "    return model_list, coherence_values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qMxN7sHoYRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start,stop,step=30,110,10\n",
        "model_list, coherence_values = compute_coherence_values(train_set, stop, start, step)\n",
        "\n",
        "# Show graph\n",
        "plt.plot(range(start, stop, step), coherence_values)\n",
        "plt.xlabel(\"Number of Topics\")\n",
        "plt.ylabel(\"Coherence score\")\n",
        "plt.legend((\"coherence_values\"), loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}